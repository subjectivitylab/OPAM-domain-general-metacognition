{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bfb4c27",
   "metadata": {},
   "source": [
    "## Data Handling Script\n",
    "\n",
    "**Purpose:**  (1) Extract necessary metrics from all multi-domain studies and export to `.csv` for further exploration, (2) calculate statistics on amount of data analyzed – **all with hmetad calculation**\n",
    "\n",
    "Author: Saurish Srivastava @ [Subjectivity Lab](https://subjectivity.sites.northeastern.edu/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23981b6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# install packages\n",
    "!pip3 install numpy\n",
    "!pip3 install pandas\n",
    "!pip3 install seaborn\n",
    "!pip3 install matplotlib\n",
    "!pip3 install scipy\n",
    "!pip3 install arviz\n",
    "!pip3 install numpyro\n",
    "!pip3 install pymc\n",
    "!pip3 install aesara\n",
    "!pip3 install git+https://github.com/embodied-computation-group/metadPy.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9acf132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import numpyro\n",
    "import scipy.stats as st\n",
    "from metadPy.bayesian import hmetad\n",
    "\n",
    "from metadPy.mle import fit_metad, metad\n",
    "from metadPy import load_dataset\n",
    "from metadPy.utils import trials2counts\n",
    "from metadPy.plotting import plot_confidence, plot_roc\n",
    "from metadPy.sdt import scores, rates, dprime, criterion, roc_auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from functools import partial, reduce\n",
    "\n",
    "# Set the number of cores used by Numpyro\n",
    "numpyro.set_host_device_count(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f18c1",
   "metadata": {},
   "source": [
    "## Define data handling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc9469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGroupData(data, nRatings, export):\n",
    "    \"\"\"\n",
    "    For dataframe {data} & int {nRatings} & string {export}: finds scores, rates, dprime, metad, \n",
    "    criterion, mratio, and mdiff for each subject and export it to {export} filepath.\n",
    "    Returns: a dataframe with above variables formatted as {domain}_{variable} and exports to {export} location\n",
    "    \"\"\"\n",
    "    # get domains\n",
    "    domains = list(data['Task'].unique())\n",
    "    \n",
    "    # create temporary dictionary\n",
    "    temp_dict = {}\n",
    "    \n",
    "    for domain in domains:\n",
    "        domain_data = data.loc[data['Task'] == domain] # only get proper domain\n",
    "        domain_data = domain_data.reset_index(drop=True) # reset indexes\n",
    "        # iterate through each subject in the data\n",
    "        temp_list = []\n",
    "        print(f\"{domain.capitalize()}\\n------------\")\n",
    "        for i in list(domain_data['Subject'].unique()):\n",
    "            temp_data = domain_data.loc[domain_data['Subject'] == i]\n",
    "            # if metad function does not return error, continue with this subject\n",
    "            try:\n",
    "                model, traces = hmetad(\n",
    "                    data=temp_data,\n",
    "                    nRatings=nRatings,\n",
    "                    stimuli=\"Stimuli\",\n",
    "                    accuracy=\"Accuracy\",\n",
    "                    confidence=\"Confidence\",\n",
    "                    subject=\"Subject\",\n",
    "                    backend=\"numpyro\",\n",
    "                )\n",
    "            except:\n",
    "                continue\n",
    "            else:\n",
    "                temp_dprime = az.summary(traces)['mean']['d1[0]']\n",
    "                temp_criterion = az.summary(traces)['mean']['c1[0]']\n",
    "                temp_metadprime = az.summary(traces)['mean']['meta_d[0]']\n",
    "                temp_mratio = az.summary(traces)['mean']['m_ratio[0]']\n",
    "                temp_logmratio = az.summary(traces)['mean']['log_m_ratio[0]']\n",
    "                print(f\"Done: Subject {i}\")\n",
    "                \n",
    "                temp_list.append([i, temp_dprime, temp_criterion, temp_metadprime,\n",
    "                                  temp_mratio, temp_logmratio])\n",
    "\n",
    "        # create pandas dataframe from list data\n",
    "        groupData = pd.DataFrame(temp_list, columns=['Index', domain + '_dprime', domain + '_criterion',\n",
    "                                               domain + '_metad', domain + '_mratio', domain + '_log_mratio'])\n",
    "        # change index name\n",
    "        groupData = groupData.set_index('Index')\n",
    "        groupData.index.name=\"Subject\"\n",
    "        \n",
    "        # add to dictionary\n",
    "        temp_dict[domain] = groupData\n",
    "        \n",
    "        print(f\"------------\\nCompleted: {domain.capitalize()}\\n------------\")\n",
    "    \n",
    "    # merge data\n",
    "    my_reduce = partial(pd.merge, on='Subject', how='outer')\n",
    "    fullData = reduce(my_reduce, temp_dict.values())\n",
    "    \n",
    "    # export data\n",
    "    \n",
    "    fullData.to_csv('../../exports/hmetad_' + export + '.csv')\n",
    "    \n",
    "    print(f\"Exported: 'hmetad_{export}.csv'\")\n",
    "    \n",
    "    return fullData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getAnalyzedTrials(data, domains)\n",
    "#     \"\"\"\n",
    "#     For dataframe 'data': find out the number of trials that are analyzed and the number of\n",
    "#     trials that are excluded during metad calculations\n",
    "#     Prints: # of subjects, # of recorded trials, # of analyzed and non-analyzed trials,\n",
    "#     # of subjects not analyzed, and percentage accounted for & their difference in %\n",
    "#     \"\"\"\n",
    "    \n",
    "#     domains = list(data['Task'].unique())\n",
    "#     temp_list = []\n",
    "#     subjectCounter = 0\n",
    "#     skipped_subject = []\n",
    "#     for domain in domains: \n",
    "#         domain_data = data.loc[data['Task'] == domain] # only get proper domain\n",
    "#         domain_data = domain_data.reset_index(drop=True) # reset indexes\n",
    "        \n",
    "#         # iterate through each subject in the data\n",
    "#         for i in list(domain_data['Subject'].unique()):\n",
    "#             temp_data = domain_data.loc[domain_data['Subject'] == i]\n",
    "#             [nR_S1, nR_S2] = trials2counts(data=temp_data.copy(), stimuli=\"Stimuli\", responses=\"Responses\",\n",
    "#                        confidence=\"Confidence\", nRatings=nRatings, padding=True)\n",
    "#             # if metad function does not return error, continue with this subject\n",
    "#             try:\n",
    "#                 fit_metad(nR_S1,nR_S2, nRatings=nRatings, nCriteria=int(2 * nRatings - 1))\n",
    "#             except:\n",
    "#                 skipped_subject.append(\"Subject \" + str(i) + \" @ \" + domain)\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 subjectCounter += 1\n",
    "#                 temp_list.append(temp_data.shape[0])\n",
    "        \n",
    "#         print(\"Completed: \" + domain)\n",
    "\n",
    "#     # calculate stats\n",
    "#     percentageAccounted = 100*(sum(temp_list)/data.shape[0])\n",
    "#     difference = 100 * (1 - (sum(temp_list)/data.shape[0]))\n",
    "    \n",
    "#     print(\"Number of subjects: \" + str(subjectCounter))\n",
    "#     print(\"Number of recorded trials: \" + str(data.shape[0]))\n",
    "#     print(\"Number of analyzed trials: \" + str(sum(temp_list)))\n",
    "#     print(\"Number of non-analyzed trials: \" + str(int(data.shape[0] - sum(temp_list))))\n",
    "#     print(\"Subjects not analyzed (@ domain): \" + str(skipped_subject))\n",
    "#     print(\"Percentage accounted for: \" + str(percentageAccounted) + \"%\")\n",
    "#     print(\"Difference (%): \" + str(difference) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ff17d4",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "### `Arbuzova_unpub_3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7669ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "data = pd.read_csv(\"../../Confidence Database/data_Arbuzova_unpub_3.csv\",\n",
    "                   usecols=['Subj_idx', 'Stimulus', 'Response', 'Confidence', 'Task'])\n",
    "data = data.rename(columns={\"Subj_idx\": \"Subject\", \"Stimulus\": \"Stimuli\", \"Response\": \"Responses\"})\n",
    "\n",
    "# drop all NaNs\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "# change dataset's 2s->1s and 1s->0s bc metadpy works with 0s and 1s\n",
    "data['Stimuli'] = data['Stimuli'].map({1:0, 2:1})\n",
    "data['Responses'] = data['Responses'].map({1:0, 2:1})\n",
    "\n",
    "# create an accuracy column bc it is easier to work with\n",
    "data['Accuracy'] = np.where((data['Stimuli'] == data['Responses']), 1, 0)\n",
    "\n",
    "# get data in order by subject\n",
    "data = data.sort_values(by=['Subject']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa2aed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getGroupData(data=data, nRatings=4, export='Arbuzova_unpub_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e596b3",
   "metadata": {},
   "source": [
    "### `Mazancieux_2018`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b5e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "data = pd.read_csv(\"../Confidence Database/data_Mazancieux_2018.csv\",\n",
    "                   usecols=['Subj_idx', 'Stimulus', 'Response', 'Confidence', 'Task'])\n",
    "data = data.rename(columns={\"Subj_idx\": \"Subject\", \"Stimulus\": \"Stimuli\", \"Response\": \"Responses\"})\n",
    "\n",
    "# drop all NaNs\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "# change dataset's 2s->1s and 1s->0s bc metadpy works with 0s and 1s\n",
    "data['Stimuli'] = data['Stimuli'].map({1:0, 2:1})\n",
    "data['Responses'] = data['Responses'].map({1:0, 2:1})\n",
    "\n",
    "# add 1 to each confidence rating\n",
    "data['Confidence'] = data['Confidence'] + 1\n",
    "\n",
    "# create an accuracy column bc it is easier to work with\n",
    "data['Accuracy'] = np.where((data['Stimuli'] == data['Responses']), 1, 0)\n",
    "\n",
    "# get data in order by subject\n",
    "data = data.sort_values(by=['Subject']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f43f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getGroupData(data=data, nRatings=11, export='Mazancieux_2018')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd07b7",
   "metadata": {},
   "source": [
    "### `Sadeghi_2017`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3877733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "data = pd.read_csv(\"../Confidence Database/data_Sadeghi_2017_memory.csv\",\n",
    "                   usecols=['Subj_idx', 'Stimulus', 'Response', 'Confidence', 'group'])\n",
    "\n",
    "data2 = pd.read_csv(\"../Confidence Database/data_Sadeghi_2017_perception.csv\",\n",
    "                   usecols=['Subj_idx', 'Stimulus', 'Response', 'Confidence', 'group'])\n",
    "\n",
    "data = data.rename(columns={\"Subj_idx\": \"Subject\", \"Stimulus\": \"Stimuli\", \"Response\": \"Responses\", \"group\": \"Task\"})\n",
    "\n",
    "data2 = data2.rename(columns={\"Subj_idx\": \"Subject\", \"Stimulus\": \"Stimuli\", \"Response\": \"Responses\", \"group\": \"Task\"})\n",
    "\n",
    "\n",
    "# get only control patients\n",
    "data = data.loc[data['Task'] == 'control']\n",
    "data2 = data2.loc[data2['Task'] == 'control']\n",
    "\n",
    "# drop all NaNs\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "data2 = data2.dropna().reset_index(drop=True)\n",
    "\n",
    "# change task values according to the dataset\n",
    "data['Task'] = 'memory'\n",
    "data2['Task'] = 'perception'\n",
    "\n",
    "# change perception dataset's 2s->1s and 1s->0s bc metadpy works with 0s and 1s\n",
    "data2['Stimuli'] = data2['Stimuli'].map({1:0, 2:1})\n",
    "data2['Responses'] = data2['Responses'].map({1:0, 2:1})\n",
    "\n",
    "# merge all data into just 'data' dataframe\n",
    "data = data.append(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36146ede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getGroupData(data=data, nRatings=6, export='Sadeghi_2017')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3624bb4",
   "metadata": {},
   "source": [
    "### `Samaha_2016`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80dfbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "data = pd.read_csv(\"../Confidence Database/data_Samaha_2016.csv\",\n",
    "                   usecols=['Subj_idx', 'Stimulus', 'Response', 'Confidence', 'Task', 'Condition', 'Accuracy'])\n",
    "data = data.rename(columns={\"Subj_idx\": \"Subject\", \"Stimulus\": \"Stimuli\", \"Response\": \"Responses\"})\n",
    "\n",
    "# drop all NaNs\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "# change dataset's -45s->0s and 45s->1s bc metadpy works with 0s and 1s\n",
    "data['Stimuli'] = data['Stimuli'].map({-45:0, 45:1, 0:0, 1:1})\n",
    "data['Responses'] = data['Responses'].map({-45:0, 45:1, 0:0, 1:1})\n",
    "\n",
    "# rename tasks based on conditions - 0.5 -> low; 1 -> high\n",
    "data['Task'] = np.where(data['Task'].eq(\"percept\") & data['Condition'].eq(0.5), 'percept_low', data['Task'])\n",
    "data['Task'] = np.where(data['Task'].eq(\"percept\") & data['Condition'].eq(1), 'percept_high', data['Task'])\n",
    "data['Task'] = np.where(data['Task'].eq(\"wm\") & data['Condition'].eq(0.5), 'wm_low', data['Task'])\n",
    "data['Task'] = np.where(data['Task'].eq(\"wm\") & data['Condition'].eq(1), 'wm_high', data['Task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9507d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "getGroupData(data=data, nRatings=4, export='Samaha_2016')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3c01ac",
   "metadata": {},
   "source": [
    "### `Samaha_2017_exp3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cd692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "data = pd.read_csv(\"../Confidence Database/data_Samaha_2017_exp3.csv\",\n",
    "                   usecols=['Subj_idx', 'Stimulus', 'Response', 'Confidence', 'Task'])\n",
    "data = data.rename(columns={\"Subj_idx\": \"Subject\", \"Stimulus\": \"Stimuli\", \"Response\": \"Responses\"})\n",
    "\n",
    "# drop all NaNs\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "# change dataset's values bc metadpy works with 0s and 1s\n",
    "data['Stimuli'] = data['Stimuli'].map({-1:0, 0:0, 1:1})\n",
    "data['Responses'] = data['Responses'].map({-1:0, 0:0, 1:1})\n",
    "\n",
    "# create an accuracy column bc it is easier to work with\n",
    "data['Accuracy'] = np.where((data['Stimuli'] == data['Responses']), 1, 0)\n",
    "\n",
    "# get data in order by subject\n",
    "data = data.sort_values(by=['Subject'])\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cccb5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getGroupData(data=data, nRatings=4, export='Samaha_2017_exp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7f499",
   "metadata": {},
   "source": [
    "### `Schmidt_2019`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4cb61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "data = pd.read_csv(\"../Confidence Database/data_Schmidt_2019_memory.csv\",\n",
    "                   usecols=['Subj_idx', 'Stimulus', 'Response', 'Confidence', 'Accuracy', 'Condition'])\n",
    "\n",
    "data2 = pd.read_csv(\"../Confidence Database/data_Schmidt_2019_perception.csv\",\n",
    "                   usecols=['Subj_idx', 'Stimulus', 'Response', 'Confidence', 'Accuracy', 'Condition'])\n",
    "\n",
    "data = data.rename(columns={\"Subj_idx\": \"Subject\", \"Stimulus\": \"Stimuli\", \"Response\": \"Responses\",\n",
    "                            \"Condition\": \"Task\"})\n",
    "\n",
    "data2 = data2.rename(columns={\"Subj_idx\": \"Subject\", \"Stimulus\": \"Stimuli\", \"Response\": \"Responses\",\n",
    "                              \"Condition\": \"Task\"})\n",
    "\n",
    "# get only first 200 trials for memory bc they are 'pre-training'\n",
    "data = data.groupby('Subject').head(200)\n",
    "\n",
    "# get only first 300 trials for perception bc they are 'pre-training'\n",
    "data2 = data2.groupby('Subject').head(300)\n",
    "\n",
    "# drop all NaNs\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "data2 = data2.dropna().reset_index(drop=True)\n",
    "\n",
    "# change task values according to the dataset\n",
    "data['Task'] = 'memory'\n",
    "data2['Task'] = 'perception'\n",
    "\n",
    "# change dataset's 2s->1s and 1s->0s bc metadpy works with 0s and 1s\n",
    "data['Stimuli'] = data['Stimuli'].map({1:0, 2:1})\n",
    "data['Responses'] = data['Responses'].map({1:0, 2:1})\n",
    "\n",
    "data2['Stimuli'] = data2['Stimuli'].map({1:0, 2:1})\n",
    "data2['Responses'] = data2['Responses'].map({1:0, 2:1})\n",
    "\n",
    "# merge all data into just 'data' dataframe\n",
    "data = data.append(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b430dbcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getGroupData(data=data, nRatings=4, export='Schmidt_2019')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eba4c6",
   "metadata": {},
   "source": [
    "### `Skora_2016`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97a9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "data = pd.read_csv(\"../Confidence Database/data_Skora_2016.csv\",\n",
    "                   usecols=['Subj_idx', 'Stimulus', 'Response', 'Confidence', 'Condition', 'Accuracy'])\n",
    "data = data.rename(columns={\"Subj_idx\": \"Subject\", \"Stimulus\": \"Stimuli\", \"Response\": \"Responses\", \"Condition\": \"Task\"})\n",
    "\n",
    "# get data in order by subject\n",
    "data = data.sort_values(by=['Subject']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4eac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "getGroupData(data=data, nRatings=4, export='Skora_2016')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b845f49",
   "metadata": {},
   "source": [
    "### `Xu_2019_Exp2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f5a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "data = pd.read_csv(\"../Confidence Database/data_Xu_2019_Exp2.csv\",\n",
    "                   usecols=['Subj_idx', 'Stimulus', 'Response', 'Confidence', 'Task', 'Condition'])\n",
    "data = data.rename(columns={\"Subj_idx\": \"Subject\", \"Stimulus\": \"Stimuli\", \"Response\": \"Responses\"})\n",
    "\n",
    "# drop all NaNs\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "# change dataset's 2s->1s and 1s->0s bc metadpy works with 0s and 1s\n",
    "data['Stimuli'] = data['Stimuli'].map({1:0, 2:1})\n",
    "data['Responses'] = data['Responses'].map({1:0, 2:1})\n",
    "\n",
    "# create an accuracy column bc it is easier to work with\n",
    "data['Accuracy'] = np.where((data['Stimuli'] == data['Responses']), 1, 0)\n",
    "\n",
    "# rename tasks based on conditions - 0.5 -> low; 1 -> high\n",
    "data['Task'] = np.where(data['Task'].eq(\"N\") & data['Condition'].eq(\"Incongruent\"), 'N_low', data['Task'])\n",
    "data['Task'] = np.where(data['Task'].eq(\"N\") & data['Condition'].eq(\"Congruent\"), 'N_high', data['Task'])\n",
    "data['Task'] = np.where(data['Task'].eq(\"C\") & data['Condition'].eq(\"Incongruent\"), 'C_low', data['Task'])\n",
    "data['Task'] = np.where(data['Task'].eq(\"C\") & data['Condition'].eq(\"Congruent\"), 'C_high', data['Task'])\n",
    "\n",
    "# get data in order by subject\n",
    "data = data.sort_values(by=['Subject']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdfa3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "getGroupData(data=data, nRatings=4, export='Xu_2019_Exp2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673b09d7",
   "metadata": {},
   "source": [
    "### `Ye_2018`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578c8c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "data = pd.read_csv(\"../Confidence Database/data_Ye_2018.csv\",\n",
    "                   usecols=['Subj_idx', 'Stimulus', 'Response', 'Confidence', 'Task', 'Accuracy'])\n",
    "data = data.rename(columns={\"Subj_idx\": \"Subject\", \"Stimulus\": \"Stimuli\", \"Response\": \"Responses\"})\n",
    "\n",
    "# drop all NaNs\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "# change dataset's 2s->1s and 1s->0s bc metadpy works with 0s and 1s\n",
    "data['Stimuli'] = data['Stimuli'].map({1:0, 2:1})\n",
    "data['Responses'] = data['Responses'].map({1:0, 2:1})\n",
    "\n",
    "# get data in order by subject\n",
    "data = data.sort_values(by=['Subject']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeeb784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getGroupData(data=data, nRatings=4, export='Ye_2018')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
