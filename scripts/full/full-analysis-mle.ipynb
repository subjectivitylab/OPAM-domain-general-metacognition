{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bf90719",
   "metadata": {},
   "source": [
    "## Full Confidence Database Analysis\n",
    "\n",
    "**Purpose:** Analyze meta-memory and meta-perception within all studies in the database to explore similarities and differences within the metacognition of memory/perception.\n",
    "- this script extracts metad and dprime from *all* memory and perception datasets in the database\n",
    "\n",
    "Author: Saurish Srivastava @ [Subjectivity Lab](https://subjectivity.sites.northeastern.edu/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84887028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages\n",
    "!pip3 install numpy\n",
    "!pip3 install pandas\n",
    "!pip3 install sklearn\n",
    "!pip3 install git+https://github.com/embodied-computation-group/metadPy.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a503c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from metadPy.mle import fit_metad, metad\n",
    "from metadPy.utils import trials2counts, discreteRatings\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5c0822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in datasets\n",
    "databaseInfo = pd.read_csv('../../Confidence Database/Database_Information.csv',\n",
    "                           usecols=['Category', 'Name_in_database', 'Confidence_scale'])\n",
    "# get all datasets with perception/memory\n",
    "databaseInfo = databaseInfo.loc[(databaseInfo['Category'] == 'Perception') | (databaseInfo['Category'] == 'Memory')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41feaf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "requiredCols = ['Subj_idx', 'Stimulus', 'Response', 'Confidence']\n",
    "finalDatasets = []\n",
    "\n",
    "# get final dataset names by seeing if the dataset has each of the columns in 'requiredCols'\n",
    "for i, dataName in enumerate(list(databaseInfo['Name_in_database'])):\n",
    "    try:\n",
    "        data = pd.read_csv('../../Confidence Database/data_' + dataName + '.csv', usecols=requiredCols)\n",
    "    except:\n",
    "        continue\n",
    "    else:\n",
    "        finalDatasets.append(dataName)\n",
    "\n",
    "# get rid of datasets that include subjects with clinical disorders\n",
    "finalDatasets = list(set(finalDatasets) - set(['Chandravadia_2020', 'Locke_2020', 'Wang_2017_NatComm']))\n",
    "\n",
    "# only save datasets with required columns\n",
    "databaseInfo = databaseInfo[databaseInfo['Name_in_database'].isin(finalDatasets)].reset_index(drop=True)\n",
    "\n",
    "# add mixed datasets that include memory/perception\n",
    "mixed_data = {'Category':['Mixed', 'Mixed', 'Mixed', 'Mixed', 'Mixed'],\n",
    "        'Name_in_database':['Mazancieux_2018', 'Arbuzova_unpub_3', 'Samaha_2016', 'Samaha_2017_exp3', 'Ye_2018'],\n",
    "        'Confidence_scale':['11-point', '4-point', '4-point', '4-point', '4-point']\n",
    "       }\n",
    "  \n",
    "df_mixed_data = pd.DataFrame(mixed_data)\n",
    "databaseInfo = databaseInfo.append(df_mixed_data,ignore_index=True)\n",
    "databaseInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset(data, dataName, nRatings):\n",
    "    \"\"\"\n",
    "    Create a dataset with the subjects from dataName and their respective dprime and metad values\n",
    "    \"\"\"\n",
    "    domain_list = []\n",
    "    metadprime_list = []\n",
    "    dprime_list = []\n",
    "    # if there is only one domain\n",
    "    if 'Domain' not in list(data.columns):\n",
    "        for i in list(data['Subject'].unique()):\n",
    "            temp_data = data.loc[data['Subject'] == i]\n",
    "            [nR_S1, nR_S2] = trials2counts(data=temp_data.copy(), stimuli=\"Stimuli\", responses=\"Responses\",\n",
    "                                   confidence=\"Confidence\", nRatings=nRatings, padding=True)\n",
    "            # if metad function does not return error, continue with this subject\n",
    "            try:\n",
    "                temp_fit = fit_metad(nR_S1,nR_S2, nRatings=nRatings, nCriteria=int(2 * nRatings - 1))\n",
    "            except:\n",
    "                continue\n",
    "            else:\n",
    "                metadprime_list.append(temp_fit['meta_d'])\n",
    "                dprime_list.append(temp_fit['dprime'])\n",
    "                domain_temp = databaseInfo.loc[databaseInfo['Name_in_database'] == dataName, 'Category'].values[0]\n",
    "                domain_list.append(domain_temp)\n",
    "        data_list = [dataName] * len(metadprime_list)\n",
    "    # if there are multiple domains\n",
    "    else:\n",
    "        domains = list(data['Domain'].unique())\n",
    "        for domain in domains:\n",
    "            domain_data = data.loc[data['Domain'] == domain] # only get proper domain\n",
    "            domain_data = domain_data.reset_index(drop=True) # reset indexes\n",
    "            # iterate through each subject in the data\n",
    "            for i in list(domain_data['Subject'].unique()):\n",
    "                temp_data = domain_data.loc[domain_data['Subject'] == i]\n",
    "                [nR_S1, nR_S2] = trials2counts(data=temp_data.copy(), stimuli=\"Stimuli\", responses=\"Responses\",\n",
    "                                       confidence=\"Confidence\", nRatings=nRatings, padding=True)\n",
    "                # if metad function does not return error, continue with this subject\n",
    "                try:\n",
    "                    temp_fit = fit_metad(nR_S1,nR_S2, nRatings=nRatings, nCriteria=int(2 * nRatings - 1))\n",
    "                except:\n",
    "                    continue\n",
    "                else:\n",
    "                    metadprime_list.append(temp_fit['meta_d'])\n",
    "                    dprime_list.append(temp_fit['dprime'])\n",
    "                    if type(domain) == str:\n",
    "                        domain = domain.capitalize()\n",
    "                    domain_list.append(domain)\n",
    "        data_list = [dataName] * len(metadprime_list)\n",
    "    \n",
    "    # create dataframe\n",
    "    product = pd.DataFrame({'dprime': dprime_list, 'metad': metadprime_list,\n",
    "                            'domain': domain_list,'dataset': data_list})\n",
    "    \n",
    "    return product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9326fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metricsList = ['Subj_idx', 'Stimulus', 'Response', 'Confidence', 'Task', 'Group', 'group', 'Type']\n",
    "# concat data function\n",
    "masterData = pd.DataFrame()\n",
    "for i, dataName in enumerate(list(databaseInfo['Name_in_database'])):\n",
    "    # read in data\n",
    "    try:\n",
    "        data = pd.read_csv('../../Confidence Database/data_' + dataName + '.csv', usecols=lambda x: x in metricsList)\n",
    "    except:\n",
    "        continue\n",
    "    else:\n",
    "        print(\"Start: \" + dataName)\n",
    "        data = data.rename(columns={\"Subj_idx\": \"Subject\", \"Stimulus\": \"Stimuli\", \"Response\": \"Responses\"})\n",
    "\n",
    "        # convert {string} stimuli to int (0 or 1) [keeps values the same if already in 0 or 1 format]\n",
    "        data['Stimuli'] = LabelEncoder().fit_transform(data['Stimuli'])\n",
    "        data['Responses'] = LabelEncoder().fit_transform(data['Responses'])\n",
    "        \n",
    "        # create accuracy column\n",
    "        data['Accuracy'] = np.where((data['Stimuli'] == data['Responses']), 1, 0)\n",
    "\n",
    "        # drop all NaNs\n",
    "        data = data.dropna().reset_index(drop=True)\n",
    "        # get data in order by subject\n",
    "        data = data.sort_values(by=['Subject']).reset_index(drop=True) \n",
    "        # get confidence ratings\n",
    "        confidence_val = databaseInfo.loc[databaseInfo['Name_in_database'] == dataName, 'Confidence_scale'].values[0]\n",
    "        if 'continuous' in confidence_val:\n",
    "            newRatings = discreteRatings(ratings=data['Confidence'].values)[0]\n",
    "            data['Confidence'] = newRatings\n",
    "            confidenceRatings = 4\n",
    "        else:\n",
    "            confidenceRatings = int(confidence_val[0])\n",
    "            \n",
    "        # check if confidence scale starts from 0 or 1 (if starts from 0, add 1 to each confidence value)\n",
    "        if data['Confidence'].min() == 0:\n",
    "            data['Confidence'] = data['Confidence'] + 1\n",
    "        \n",
    "        # centralize domains (i.e. 'task' or 'group' -> 'domain' for further processing)\n",
    "        if len(list(data.columns)) > 5:\n",
    "            # rename it to \"Domain\"\n",
    "            data = data.rename(columns={data.columns[4]: \"Domain\"})\n",
    "        \n",
    "        # create datasets\n",
    "        product = createDataset(data=data, dataName=dataName, nRatings=confidenceRatings)   \n",
    "        \n",
    "        # concat data\n",
    "        masterData = pd.concat([masterData, product])\n",
    "        \n",
    "    print('Done: ' + dataName + ' ('+ str(i+1) + '/' + str(len(list(databaseInfo['Name_in_database']))) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a573d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data to csv file\n",
    "masterData.to_csv('../../exports/masterData.csv')\n",
    "masterData"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
